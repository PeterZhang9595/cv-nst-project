在这里我尝试进行一些更精细化的处理，即先通过image segmentation生成一份内容图的掩码，然后在后续更新图片的时候，对不同区域的像素使用不同的loss函数进行反向更新。

至于如何针对content和style进行更新，我现在的想法是：
1. 使用一些预训练好的模型生成图像的前景和背景掩码M。
2. 前向传播，然后在反向传播的时候，计算content loss的时候利用掩码，给$M \gt 0$部分更多的更新权重，而计算style loss的时候给$M = 0$部分更多的权重。
这里就出现了一个问题：
由于CNN会改变图片的大小，所以我们应该在哪里乘上掩码矩阵M？
1. 想法1：按照原来的方法，把loss对原图的梯度传回原图，然后使用掩码乘上进行content loss的更新
2. 想法2：想法1虽然简便，但是容易损失信息，我们不如在每个loss层直接使用掩码再往回传。
但是这里又出现问题了，我们的掩码大小是M，和特征层大小不一样。所以我们应该把M采样到特征层的大小，然后乘上掩码再反传回去。

刚刚尝试了一下，由于MASK-RCNN的训练集相对有限，所以对于大多数照片的识别能力不是太好，我们这里尝试一下SAM试试。
效果也不太行。
突然发现很多时候对于一些精细化的任务还是传统方法更好一点。最终使用的算法是Canny。